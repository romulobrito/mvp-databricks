{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0ad146e-8eea-4942-a33b-12af737d8c36",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PARTE 1: CARREGANDO ARQUIVOS EXCEL ===\n\n[OK] Arquivos encontrados em: /Workspace/Users/romulobrtsilva@gmail.com/Drafts/raw_data\n\nCaminhos configurados:\n  Ciclo01.xlsx: /Workspace/Users/romulobrtsilva@gmail.com/Drafts/raw_data/Ciclo01.xlsx\n  Ciclo02.xlsx: /Workspace/Users/romulobrtsilva@gmail.com/Drafts/raw_data/Ciclo02.xlsx\n\n[OK] openpyxl ja instalado\n\nCarregando Ciclo01.xlsx...\nCiclo01.xlsx: 752,223 linhas\nCarregando Ciclo02.xlsx...\nCiclo02.xlsx: 796,343 linhas\n\nConcatenando DataFrames...\n\nDataFrame concatenado criado:\n  Total de linhas: 1,548,566\n  Total de colunas: 9\n  Colunas disponiveis: ['DataEv', 'HoraEv', 'CodRecurso', 'Recursos', 'Latitude', 'Longitude', 'SiglaRodovia', 'Sentido', 'KM']\n\n=== PARTE 2: VALIDACAO DOS DADOS ===\n\nPrimeiras 5 linhas:\n      DataEv    HoraEv  CodRecurso  ... SiglaRodovia  Sentido       KM\n0 2025-05-01  00:00:05         135  ...    BR-153/GO        S  212+768\n1 2025-05-01  00:00:07         134  ...    BR-153/GO        N  367+530\n2 2025-05-01  00:00:08         131  ...    BR-153/TO        S  677+437\n3 2025-05-01  00:00:12         259  ...    BR-153/TO        S  765+222\n4 2025-05-01  00:00:15         135  ...    BR-153/GO        N  212+770\n\n[5 rows x 9 columns]\n\nInformacoes do DataFrame:\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1548566 entries, 0 to 1548565\nData columns (total 9 columns):\n #   Column        Non-Null Count    Dtype         \n---  ------        --------------    -----         \n 0   DataEv        1548566 non-null  datetime64[ns]\n 1   HoraEv        1548566 non-null  object        \n 2   CodRecurso    1548566 non-null  int64         \n 3   Recursos      1548566 non-null  object        \n 4   Latitude      1548566 non-null  float64       \n 5   Longitude     1548566 non-null  float64       \n 6   SiglaRodovia  1548566 non-null  object        \n 7   Sentido       1548566 non-null  object        \n 8   KM            1548566 non-null  object        \ndtypes: datetime64[ns](1), float64(2), int64(1), object(5)\nmemory usage: 106.3+ MB\nNone\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Notebook MVP 00 - Gerar tabela Bronze (ciclos_concatenados).\n",
    "\n",
    "Este notebook le e concatena os arquivos Excel Ciclo01.xlsx e Ciclo02.xlsx\n",
    "e gera o arquivo Parquet Bronze no diretorio mvp/dados_bronze.\n",
    "\n",
    "Toda a logica esta incorporada diretamente, sem necessidade de importar modulos externos.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "print(\"=== PARTE 1: CARREGANDO ARQUIVOS EXCEL ===\\n\")\n",
    "\n",
    "caminhos_possiveis = [\n",
    "    \"/Workspace/Users/romulobrtsilva@gmail.com/Drafts/raw_data\",\n",
    "]\n",
    "    # caminho_ciclo01 =  \"/Workspace/Users/romulobrtsilva@gmail.com/Drafts/raw_data/Ciclo01.xlsx\"\n",
    "    # caminho_ciclo02 = \"/Workspace/Users/romulobrtsilva@gmail.com/Drafts/raw_data/Ciclo02.xlsx\"\n",
    "caminho_ciclo01 = None\n",
    "caminho_ciclo02 = None\n",
    "\n",
    "for caminho_base in caminhos_possiveis:\n",
    "    arquivo1 = os.path.join(caminho_base, \"Ciclo01.xlsx\")\n",
    "    arquivo2 = os.path.join(caminho_base, \"Ciclo02.xlsx\")\n",
    "    if os.path.exists(arquivo1) and os.path.exists(arquivo2):\n",
    "        caminho_ciclo01 = arquivo1\n",
    "        caminho_ciclo02 = arquivo2\n",
    "        print(f\"[OK] Arquivos encontrados em: {caminho_base}\")\n",
    "        break\n",
    "\n",
    "if caminho_ciclo01 is None or caminho_ciclo02 is None:\n",
    "    raise FileNotFoundError(\n",
    "        \"Arquivos Excel (Ciclo01.xlsx e Ciclo02.xlsx) nao encontrados.\\n\"\n",
    "        \"Verifique se os arquivos estao em uma das seguintes localizacoes:\\n\"\n",
    "        \"  - /dbfs/Workspace/Users/romulobrtsilva@gmail.com/Drafts/raw_data\\n\"\n",
    "        \"  - /dbfs/FileStore/shared_uploads\\n\"\n",
    "        \"  - /dbfs/mnt/mvp/dados_bronze\"\n",
    "    )\n",
    "\n",
    "print(f\"\\nCaminhos configurados:\")\n",
    "print(f\"  Ciclo01.xlsx: {caminho_ciclo01}\")\n",
    "print(f\"  Ciclo02.xlsx: {caminho_ciclo02}\")\n",
    "\n",
    "# Instalar openpyxl se necessario\n",
    "try:\n",
    "    import openpyxl\n",
    "    print(\"\\n[OK] openpyxl ja instalado\")\n",
    "except ImportError:\n",
    "    print(\"\\nInstalando openpyxl...\")\n",
    "    %pip install openpyxl\n",
    "    import openpyxl\n",
    "\n",
    "# Carregar arquivos Excel\n",
    "print(\"\\nCarregando Ciclo01.xlsx...\")\n",
    "df_ciclo01 = pd.read_excel(caminho_ciclo01)\n",
    "print(f\"Ciclo01.xlsx: {len(df_ciclo01):,} linhas\")\n",
    "\n",
    "print(\"Carregando Ciclo02.xlsx...\")\n",
    "df_ciclo02 = pd.read_excel(caminho_ciclo02)\n",
    "print(f\"Ciclo02.xlsx: {len(df_ciclo02):,} linhas\")\n",
    "\n",
    "# Concatenar os DataFrames\n",
    "print(\"\\nConcatenando DataFrames...\")\n",
    "df_concatenado = pd.concat([df_ciclo01, df_ciclo02], ignore_index=True)\n",
    "\n",
    "print(f\"\\nDataFrame concatenado criado:\")\n",
    "print(f\"  Total de linhas: {len(df_concatenado):,}\")\n",
    "print(f\"  Total de colunas: {len(df_concatenado.columns)}\")\n",
    "print(f\"  Colunas disponiveis: {list(df_concatenado.columns)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# Validacao dos dados\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n=== PARTE 2: VALIDACAO DOS DADOS ===\\n\")\n",
    "\n",
    "print(\"Primeiras 5 linhas:\")\n",
    "print(df_concatenado.head())\n",
    "\n",
    "print(\"\\nInformacoes do DataFrame:\")\n",
    "print(df_concatenado.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9e05945-662f-4b12-b68f-4c2715801ff5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n=== PARTE 3: SALVANDO DADOS BRONZE ===\n\n[OK] Diretorio criado/verificado: /Workspace/Users/romulobrtsilva@gmail.com/Drafts/mvp/dados_bronze\nDiretorio Bronze: /Workspace/Users/romulobrtsilva@gmail.com/Drafts/mvp/dados_bronze\nArquivo Bronze de saida: /Workspace/Users/romulobrtsilva@gmail.com/Drafts/mvp/dados_bronze/ciclos_concatenados.parquet\n\nSalvando DataFrame concatenado em Parquet (Bronze)...\n[OK] Arquivo Parquet salvo em: /Workspace/Users/romulobrtsilva@gmail.com/Drafts/mvp/dados_bronze/ciclos_concatenados.parquet\n[OK] Arquivo criado com sucesso! Tamanho: 23.99 MB\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Configuracao de caminhos de saida \n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n=== PARTE 3: SALVANDO DADOS BRONZE ===\\n\")\n",
    "\n",
    "# CORRECAO: Usar caminho absoluto correto (com / no inicio)\n",
    "WORKSPACE_BASE = \"/Workspace/Users/romulobrtsilva@gmail.com/Drafts/mvp\"\n",
    "BRONZE_DIR = f\"{WORKSPACE_BASE}/dados_bronze\"  # SEM duplicacao\n",
    "\n",
    "# Criar diretorio se nao existir\n",
    "os.makedirs(BRONZE_DIR, exist_ok=True)\n",
    "print(f\"[OK] Diretorio criado/verificado: {BRONZE_DIR}\")\n",
    "\n",
    "# Caminho completo do arquivo de saida\n",
    "ARQ_BRONZE = f\"{BRONZE_DIR}/ciclos_concatenados.parquet\"\n",
    "\n",
    "print(f\"Diretorio Bronze: {BRONZE_DIR}\")\n",
    "print(f\"Arquivo Bronze de saida: {ARQ_BRONZE}\")\n",
    "\n",
    "# Salvar em Parquet\n",
    "print(\"\\nSalvando DataFrame concatenado em Parquet (Bronze)...\")\n",
    "df_concatenado.to_parquet(ARQ_BRONZE, index=False)\n",
    "print(f\"[OK] Arquivo Parquet salvo em: {ARQ_BRONZE}\")\n",
    "\n",
    "# Verificar se arquivo foi criado\n",
    "if os.path.exists(ARQ_BRONZE):\n",
    "    tamanho_mb = os.path.getsize(ARQ_BRONZE) / (1024 * 1024)\n",
    "    print(f\"[OK] Arquivo criado com sucesso! Tamanho: {tamanho_mb:.2f} MB\")\n",
    "else:\n",
    "    print(\"[ERRO] Arquivo nao foi criado!\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "00_gerar_bronze_ciclos_concatenados",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}